{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://img.kaikeba.com/web/kkb_index/img_index_logo.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 人工智能基础课机器学习 第二节课作业 股票数据清洗\n",
    "\n",
    "同学们好，本次作业的主要内容为使用pandas进行数据预处理。希望这两天你们已经从Python的课程内容中回过神来了。\n",
    "没有数据的分析是无源之水，能够熟练处理数据是成为合格的数据分析师的基本要求，希望大家在今后多多实战，成为数据大师。\n",
    "\n",
    "本次作业将使用公开标普500的股票数据。\n",
    "https://www.kaggle.com/dgawlik/nyse#prices-split-adjusted.csv\n",
    "\n",
    "作业的形式以问答为主，因为不涉及过长的代码，核心是数据的操作，所以这里没有太多的代码模板可供大家参考。\n",
    "希望大家能从搜索引擎（google/bing）问答社区（stackoverflow）或者[官方文档](https://pandas.pydata.org/pandas-docs/stable/user_guide/index.html)或者我提供的jupyter notebooks 中找到回答问题需要的方法。\n",
    "请时刻牢记数据的增删改查四种原子操作，思考我们的问题可以被如何分解。\n",
    "\n",
    "那么首先，我们要import pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 从fundemantals.csv开始！\n",
    "\n",
    "fundemantals.csv 是这些股票的年报数据\n",
    "\n",
    "请用数据回答以下问题：\n",
    "\n",
    "1. S&P500股票在2015年`net income`的均值是多少？最大值比最小值多多少？（每问10分，共计20分）\n",
    "2. S&P500股票在2016年的固定资产（fixed assets）占总资产(total assets)比例的均值是多少？固定资产占总资产比例最小的股票是的代码（ticker symbol）是什么？（每问10分，共计20分）\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.1 S&P500股票在2015年net income的均值是多少？最大值比最小值多多少？\n",
    "\n",
    "\n",
    "\n",
    "# -*- coding: UTF-8 -*-\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "net_income_2015_mean = 0\n",
    "net_income_2015_diff_max_min = 0\n",
    "\n",
    "\n",
    "# 数据预处理\n",
    "fund_df = pd.read_csv(\"fundamentals.csv\")\n",
    "fund_df = fund_df.drop_duplicates()\n",
    "fund_df = fund_df.reset_index(drop=True)\n",
    "\n",
    "fund_df.columns = fund_df.columns.str.replace(' ', '_')\n",
    "\n",
    "fund_df = fund_df[[\"Period_Ending\", \"Net_Income\"]]\n",
    "fund_df = fund_df.dropna()\n",
    "fund_df = fund_df.reset_index(drop=True)\n",
    "\n",
    "fund_df[\"Period_Ending\"] = pd.to_datetime(fund_df[\"Period_Ending\"])\n",
    "\n",
    "\n",
    "net_income_2015_mean = fund_df.query('Period_Ending >= 20160101 and Period_Ending <= 20161231')[[\"Net_Income\"]].mean()\n",
    "\n",
    "net_income_2015_diff_max_min = fund_df.query('Period_Ending >= 20160101 and Period_Ending <= 20161231')[[\"Net_Income\"]].apply(lambda x: x.max() - x.min())\n",
    "\n",
    "\n",
    "print(\"S&P500股票在2015年net income的均值为：\", np.float64(net_income_2015_mean))\n",
    "print(\"最大值与最小值的差值为：\", np.float64(net_income_2015_diff_max_min))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/><br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. S&P500股票在2016年的固定资产（fixed assets）占总资产(total assets)比例的均值是多少？固定资产占总资产比例最小的股票是的代码（ticker symbol）是什么？\n",
    "\n",
    "\n",
    "\n",
    "# -*- coding: UTF-8 -*-\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "ratio_ft_2016_mean = 0\n",
    "\n",
    "ratio_ft_2016_min = 0\n",
    "ratio_ft_2016_min_ts = []\n",
    "\n",
    "\n",
    "# 数据预处理\n",
    "fund_df = pd.read_csv(\"fundamentals.csv\")\n",
    "fund_df = fund_df.drop_duplicates()\n",
    "fund_df = fund_df.reset_index(drop=True)\n",
    "\n",
    "fund_df.columns = fund_df.columns.str.replace(' ', '_')\n",
    "\n",
    "fund_df = fund_df[[\"Ticker_Symbol\", \"Period_Ending\", \"Fixed_Assets\", \"Total_Assets\"]]\n",
    "fund_df = fund_df.dropna()\n",
    "fund_df = fund_df.reset_index(drop=True)\n",
    "\n",
    "fund_df[\"Period_Ending\"] = pd.to_datetime(fund_df[\"Period_Ending\"])\n",
    "\n",
    "\n",
    "fund_df[\"Fixed_Total\"] = fund_df[\"Fixed_Assets\"]/fund_df[\"Total_Assets\"]\n",
    "\n",
    "ratio_ft_2016_mean = fund_df.query('Period_Ending >= 20160101 and Period_Ending <= 20161231')[[\"Fixed_Total\"]].mean()\n",
    "ratio_ft_2016_mean =  np.float64(ratio_ft_2016_mean)\n",
    "\n",
    "\n",
    "ratio_ft_2016_min = fund_df.query('Period_Ending >= 20160101 and Period_Ending <= 20161231')[[\"Fixed_Total\"]].min()\n",
    "ratio_ft_2016_min = np.float64(ratio_ft_2016_min)\n",
    "\n",
    "ratio_ft_2016_min_ts = list(fund_df.query('Period_Ending >= 20160101 and Period_Ending <= 20161231 and Fixed_Total == @ ratio_ft_2016_min')[\"Ticker_Symbol\"])\n",
    "\n",
    "\n",
    "print(\"S&P500股票在2016年的固定资产（fixed assets）占总资产(total assets)比例的均值为：\", ratio_ft_2016_mean)\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"固定资产占总资产比例最小值为：\", ratio_ft_2016_min)\n",
    "print(\"固定资产占总资产比例最小的股票是的代码（ticker symbol）为：\")\n",
    "for i in range(len(ratio_ft_2016_min_ts)):\n",
    "    print(ratio_ft_2016_min_ts[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 加入securities.csv~\n",
    "\n",
    "securities.csv包含了这些股票的基本信息\n",
    "\n",
    "1. 请列举出各个sector中的加入时间最早的股票名称（10分）\n",
    "2. 请列举出每一个州中加入时间最晚的股票名称（10分）\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.1 请列举出各个sector中的加入时间最早的股票名称\n",
    "\n",
    "\n",
    "\n",
    "# -*- coding: UTF-8 -*-\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import datetime\n",
    "\n",
    "\n",
    "\n",
    "earliest = datetime.date.today()\n",
    "earliest_ts = []\n",
    "\n",
    "\n",
    "# 数据预处理\n",
    "secur_df = pd.read_csv(\"securities.csv\")\n",
    "secur_df = secur_df.drop_duplicates()\n",
    "secur_df = secur_df.reset_index(drop=True)\n",
    "\n",
    "secur_df.columns = secur_df.columns.str.replace(' ', '_')\n",
    "\n",
    "secur_df = secur_df[[\"Ticker_symbol\", \"GICS_Sector\", \"Date_first_added\"]]\n",
    "secur_df = secur_df.dropna()\n",
    "secur_df = secur_df.reset_index(drop=True)\n",
    "\n",
    "secur_df[\"Date_first_added\"] = pd.to_datetime(secur_df[\"Date_first_added\"])\n",
    "\n",
    "\n",
    "print(\"各个sector中的加入时间最早的股票名称为：\")\n",
    "\n",
    "for name, group in secur_df.groupby(secur_df[\"GICS_Sector\"]):\n",
    "    earliest = group[\"Date_first_added\"].min()\n",
    "\n",
    "    earliest_ts = list(group.query(\"Date_first_added == @ earliest\")[\"Ticker_symbol\"])\n",
    "\n",
    "    print(\"\\n\")\n",
    "    print(\"{0}:\".format(name))\n",
    "    for i in range(len(earliest_ts)):\n",
    "        print(\"{0} 加入时间 {1}\".format(earliest_ts[i], earliest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/><br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.2 请列举出每一个州中加入时间最晚的股票名称\n",
    "\n",
    "\n",
    "\n",
    "# -*- coding: UTF-8 -*-\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import datetime\n",
    "\n",
    "\n",
    "\n",
    "states_and_abbreviations = [('Alabama', 'AL'), ('Alaska', 'AK'), ('Arizona', 'AZ'), ('Arkansas', 'AR'), ('California', 'CA'), ('Colorado', 'CO'), ('Connecticut', 'CT'), ('Delaware', 'DE'), ('Florida', 'FL'), ('Georgia', 'GA'), ('Hawaii', 'HI'), ('Idaho', 'ID'), ('Illinois', 'IL'), ('Indiana', 'IN'), ('Iowa', 'IA'), ('Kansas', 'KS'), ('Kentucky', 'KY'), ('Louisiana', 'LA'), ('Maine', 'ME'), ('Maryland', 'MD'), ('Massachusetts', 'MA'), ('Michigan', 'MI'), ('Minnesota', 'MN'), ('Mississippi', 'MS'), ('Missouri', 'MO'), ('Montana', 'MT'), ('Nebraska', 'NE'), ('Nevada', 'NV'), ('New Hampshire', 'NH'), ('New Jersey', 'NJ'), ('New Mexico', 'NM'), ('New York', 'NY'), ('North Carolina', 'NC'), ('North Dakota', 'ND'), ('Ohio', 'OH'), ('Oklahoma', 'OK'), ('Oregon', 'OR'), ('Pennsylvania', 'PA'), ('Rhode Island', 'RI'), ('South Carolina', 'SC'), ('South Dakota', 'SD'), ('Tennessee', 'TN'), ('Texas', 'TX'), ('Utah', 'UT'), ('Vermont', 'VT'), ('Virginia', 'VA'), ('Washington', 'WA'), ('West Virginia', 'WV'), ('Wisconsin', 'WI'), ('Wyoming', 'WY')]\n",
    "\n",
    "# Number and punctuation.\n",
    "NP = \"1234567890!\\\"#$%&'()*+,-./:;<=>?@[\\\\]^_`{|}~，。、“”；：？！\"\n",
    "\n",
    "\n",
    "\n",
    "# 去掉数字和标点符号\n",
    "def remover(s, item=NP):\n",
    "    s_clean = \"\"\n",
    "\n",
    "    for letter in s:\n",
    "        if letter not in item:\n",
    "            s_clean += letter\n",
    "\n",
    "    return s_clean\n",
    "\n",
    "\n",
    "\n",
    "latest = datetime.date.today()\n",
    "latest_ts = []\n",
    "\n",
    "\n",
    "# 数据预处理\n",
    "secur_df = pd.read_csv(\"securities.csv\")\n",
    "secur_df = secur_df.drop_duplicates()\n",
    "secur_df = secur_df.reset_index(drop=True)\n",
    "\n",
    "secur_df.columns = secur_df.columns.str.replace(' ', '_')\n",
    "\n",
    "secur_df = secur_df[[\"Ticker_symbol\", \"Address_of_Headquarters\", \"Date_first_added\"]]\n",
    "secur_df = secur_df.dropna()\n",
    "secur_df = secur_df.reset_index(drop=True)\n",
    "\n",
    "secur_df[\"Date_first_added\"] = pd.to_datetime(secur_df[\"Date_first_added\"])\n",
    "\n",
    "\n",
    "secur_df[\"state_raw\"] = secur_df[\"Address_of_Headquarters\"].map(lambda x: x.split(\", \")[-1])\n",
    "\n",
    "\n",
    "# 只保留 50 个州，去掉 D.C. 及 United Kingdom 等其他国家地区，同时注意 NY，UT 等州缩写形式\n",
    "for i in range(len(secur_df[\"state_raw\"])):\n",
    "    status = False\n",
    "\n",
    "    for j in range(len(states_and_abbreviations)):\n",
    "        if states_and_abbreviations[j][0] in secur_df[\"state_raw\"][i] or states_and_abbreviations[j][1] in secur_df[\"state_raw\"][i]:\n",
    "            status = True\n",
    "\n",
    "    if status == False:\n",
    "        secur_df.drop(i, inplace=True)\n",
    "\n",
    "\n",
    "secur_df = secur_df.reset_index(drop=True)\n",
    "\n",
    "\n",
    "# 去除 Oklahoma[5] 等中的符号和数字\n",
    "secur_df[\"state_raw\"] = secur_df[\"state_raw\"].map(remover)\n",
    "\n",
    "\n",
    "# 将州名重命名为 州名 + 缩写，如 Arizona -> Arizona, AZ；NY -> New York, NY 等\n",
    "for i in range(len(secur_df[\"state_raw\"])):\n",
    "    for j in range(len(states_and_abbreviations)):\n",
    "        if secur_df[\"state_raw\"][i] == states_and_abbreviations[j][0] or secur_df[\"state_raw\"][i] == states_and_abbreviations[j][1]:\n",
    "            secur_df.loc[i, \"state_raw\"] = states_and_abbreviations[j][0] + \", \" + states_and_abbreviations[j][1]\n",
    "\n",
    "\n",
    "secur_df.rename({'state_raw':'state'}, axis='columns', inplace=True)\n",
    "\n",
    "\n",
    "print(\"每一个州中加入时间最晚的股票名称为：\")\n",
    "\n",
    "for name, group in secur_df.groupby(secur_df[\"state\"]):\n",
    "    latest = group[\"Date_first_added\"].max()\n",
    "\n",
    "    latest_ts = list(group.query(\"Date_first_added == @ latest\")[\"Ticker_symbol\"])\n",
    "\n",
    "    print(\"\\n\")\n",
    "    print(\"{0}:\".format(name))\n",
    "    for i in range(len(latest_ts)):\n",
    "        print(\"{0} 加入时间 {1}\".format(latest_ts[i], latest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. merge!\n",
    "\n",
    "现在你需要同时处理来自两个表中的信息了\n",
    "\n",
    "1. 请思考，合并两个表的信息的时候，我们应该用什么样的准则对其它们（10分）\n",
    "2. 请列举每个sector在2013-2016年累计Research&Development的总投入（10分）\n",
    "3. 请列举出每个sector中，在2013-2016年累计Research&development投入最大的3家公司的名称以及投入的数值（20分）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/><br/>\n",
    "3.1 请思考，合并两个表的信息的时候，我们应该用什么样的准则对其它们  \n",
    "本题采用 inner 方法合并。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/><br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.2 列举每个sector在2013-2016年累计Research&Development的总投入\n",
    "\n",
    "\n",
    "\n",
    "# -*- coding: UTF-8 -*-\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import datetime\n",
    "\n",
    "\n",
    "\n",
    "sector_2013_2016_RDsum = 0\n",
    "\n",
    "\n",
    "# 数据预处理\n",
    "fund_df = pd.read_csv(\"fundamentals.csv\")\n",
    "fund_df = fund_df.drop_duplicates()\n",
    "fund_df = fund_df.reset_index(drop=True)\n",
    "\n",
    "fund_df.columns = fund_df.columns.str.replace(' ', '_')\n",
    "\n",
    "fund_df = fund_df[[\"Ticker_Symbol\", \"Period_Ending\", \"Research_and_Development\"]]\n",
    "fund_df = fund_df.dropna()\n",
    "fund_df = fund_df.reset_index(drop=True)\n",
    "\n",
    "fund_df[\"Period_Ending\"] = pd.to_datetime(fund_df[\"Period_Ending\"])\n",
    "\n",
    "\n",
    "# 数据预处理\n",
    "secur_df = pd.read_csv(\"securities.csv\")\n",
    "secur_df = secur_df.drop_duplicates()\n",
    "secur_df = secur_df.reset_index(drop=True)\n",
    "\n",
    "secur_df.columns = secur_df.columns.str.replace(' ', '_')\n",
    "\n",
    "secur_df = secur_df[[\"Ticker_symbol\", \"GICS_Sector\"]]\n",
    "secur_df = secur_df.dropna()\n",
    "secur_df = secur_df.reset_index(drop=True)\n",
    "\n",
    "\n",
    "secur_df.rename({'Ticker_symbol':'Ticker_Symbol'}, axis='columns', inplace=True)\n",
    "\n",
    "\n",
    "# 合并\n",
    "new_df = pd.merge(fund_df[[\"Ticker_Symbol\", \"Period_Ending\", \"Research_and_Development\"]], secur_df[[\"Ticker_Symbol\", \"GICS_Sector\"]], how='inner')\n",
    "new_df = new_df.drop_duplicates()\n",
    "new_df = new_df.dropna()\n",
    "new_df = new_df.reset_index(drop=True)\n",
    "\n",
    "new_df[\"Period_Ending\"] = pd.to_datetime(new_df[\"Period_Ending\"])\n",
    "\n",
    "\n",
    "print(\"每个sector在2013-2016年累计Research&Development的总投入为：\")\n",
    "\n",
    "for name, group in new_df.groupby(new_df[\"GICS_Sector\"]):\n",
    "    sector_2013_2016_RDsum = np.float64(group.query(\"Period_Ending >= 20130101 and Period_Ending <= 20161231\")[[\"Research_and_Development\"]].sum())\n",
    "\n",
    "    print(\"\\n\")\n",
    "    print(\"Sector: {0}\".format(name))\n",
    "    print(\"2013-2016年累计Research&Development的总投入为：{0}\".format(sector_2013_2016_RDsum))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/><br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.3 请列举出每个sector中，在2013-2016年累计Research&development投入最大的3家公司的名称以及投入的数值\n",
    "\n",
    "\n",
    "\n",
    "# -*- coding: UTF-8 -*-\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import datetime\n",
    "\n",
    "\n",
    "\n",
    "count = 3\n",
    "\n",
    "inc_2013_2016_RDsum = 0\n",
    "inc_2013_2016_RDsum_ls = []\n",
    "inc_2013_2016_RDsum_dict = {}\n",
    "\n",
    "\n",
    "# 数据预处理\n",
    "fund_df = pd.read_csv(\"fundamentals.csv\")\n",
    "fund_df = fund_df.drop_duplicates()\n",
    "fund_df = fund_df.reset_index(drop=True)\n",
    "\n",
    "fund_df.columns = fund_df.columns.str.replace(' ', '_')\n",
    "\n",
    "fund_df = fund_df[[\"Ticker_Symbol\", \"Period_Ending\", \"Research_and_Development\"]]\n",
    "fund_df = fund_df.dropna()\n",
    "fund_df = fund_df.reset_index(drop=True)\n",
    "\n",
    "fund_df[\"Period_Ending\"] = pd.to_datetime(fund_df[\"Period_Ending\"])\n",
    "\n",
    "\n",
    "# 数据预处理\n",
    "secur_df = pd.read_csv(\"securities.csv\")\n",
    "secur_df = secur_df.drop_duplicates()\n",
    "secur_df = secur_df.reset_index(drop=True)\n",
    "\n",
    "secur_df.columns = secur_df.columns.str.replace(' ', '_')\n",
    "\n",
    "secur_df = secur_df[[\"Ticker_symbol\", \"Security\", \"GICS_Sector\"]]\n",
    "secur_df = secur_df.dropna()\n",
    "secur_df = secur_df.reset_index(drop=True)\n",
    "\n",
    "\n",
    "secur_df.rename({'Ticker_symbol':'Ticker_Symbol'}, axis='columns', inplace=True)\n",
    "\n",
    "\n",
    "# 合并\n",
    "new_df = pd.merge(fund_df[[\"Ticker_Symbol\", \"Period_Ending\", \"Research_and_Development\"]], secur_df[[\"Ticker_Symbol\", \"Security\", \"GICS_Sector\"]], how='inner')\n",
    "new_df = new_df.drop_duplicates()\n",
    "new_df = new_df.dropna()\n",
    "new_df = new_df.reset_index(drop=True)\n",
    "\n",
    "new_df[\"Period_Ending\"] = pd.to_datetime(new_df[\"Period_Ending\"])\n",
    "\n",
    "\n",
    "print(\"每个sector中，在2013-2016年累计Research&development投入最大的3家公司的名称以及投入的数值为：\")\n",
    "print(\"（注：若投入为零则不计入在内）\")\n",
    "\n",
    "for namei, groupi in new_df.groupby(new_df[\"GICS_Sector\"]):\n",
    "    count = 3\n",
    "    inc_2013_2016_RDsum_ls = []\n",
    "\n",
    "    for namej, groupj in groupi.groupby(groupi[\"Security\"]):\n",
    "        inc_2013_2016_RDsum = np.float64(groupj.query(\"Period_Ending >= 20130101 and Period_Ending <= 20161231\")[[\"Research_and_Development\"]].sum())\n",
    "        inc_2013_2016_RDsum_ls.append(inc_2013_2016_RDsum)\n",
    "        inc_2013_2016_RDsum_dict[namej] = inc_2013_2016_RDsum\n",
    "\n",
    "    inc_2013_2016_RDsum_ls = list(set(inc_2013_2016_RDsum_ls))\n",
    "    inc_2013_2016_RDsum_ls.sort(reverse = True)\n",
    "\n",
    "    print(\"\\n\")\n",
    "    print(\"Sector: {0}\".format(namei))\n",
    "\n",
    "    for i in range(len(inc_2013_2016_RDsum_ls)):\n",
    "        for key, value in inc_2013_2016_RDsum_dict.items():\n",
    "            if value == inc_2013_2016_RDsum_ls[i] and value != 0:\n",
    "                print(\"投入第 {0} 大的公司名称为：{1}，投入的数值为：{2}\".format(i+1, key, value))\n",
    "\n",
    "        count -= 1\n",
    "\n",
    "        if count == 0:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. 现在让我们来看看更加复杂的数据\n",
    "\n",
    "请导入price.csv，然后结合你的聪明才智回答以下问题（附加题，40分）\n",
    "\n",
    "假设你是某基金公司的老板，现在对于每只股票，你都专门安排了一位负责它的交易员。公司规定每一位交易员手中的资金要么全部买入要么全部卖出（空仓，转化为现金）。假设2016年每一位交易员手中都有10000美元，假设他们都能够看到2016年全年的数据，假设他们都能抓住每一次机会，那么请问2016年底时，赚钱最多的股票是哪一只，赚了多少钱？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: UTF-8 -*-\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import datetime\n",
    "\n",
    "\n",
    "\n",
    "initial_fund = 10000\n",
    "fund = 0\n",
    "\n",
    "fund_ls = []\n",
    "fund_dict = {}\n",
    "\n",
    "\n",
    "# 数据预处理\n",
    "prices_df = pd.read_csv(\"prices.csv\")\n",
    "prices_df = prices_df.drop_duplicates()\n",
    "prices_df = prices_df.reset_index(drop=True)\n",
    "\n",
    "prices_df.columns = prices_df.columns.str.replace(' ', '_')\n",
    "\n",
    "prices_df = prices_df[[\"date\", \"symbol\", \"low\", \"high\"]]\n",
    "prices_df = prices_df.dropna()\n",
    "prices_df = prices_df.reset_index(drop=True)\n",
    "\n",
    "prices_df[\"date\"] = pd.to_datetime(prices_df[\"date\"])\n",
    "\n",
    "\n",
    "#设每天只做一笔交易，最低买最高卖，不限量\n",
    "for name, group in prices_df.query(\"date >= 20160101 and date <= 20161231\").groupby(prices_df[\"symbol\"]):\n",
    "    fund = initial_fund\n",
    "\n",
    "    group = group.reset_index(drop=True)\n",
    "\n",
    "    for i in range(len(group)):\n",
    "        fund = (fund / group[\"low\"][i]) * group[\"high\"][i]\n",
    "\n",
    "    fund_ls.append(fund)\n",
    "    fund_dict[name] = fund\n",
    "\n",
    "\n",
    "fund_ls = list(set(fund_ls))\n",
    "fund_ls.sort(reverse = True)\n",
    "\n",
    "\n",
    "for key, value in fund_dict.items():\n",
    "    if value == fund_ls[0]:\n",
    "        print(\"赚钱最多的股票是 {0}，赚了 {1} 美元\".format(key, np.float64(value-initial_fund)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
